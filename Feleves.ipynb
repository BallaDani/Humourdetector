{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a turtle without its shell? d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 reasons the 2016 election feels so personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>Conor maynard seamlessly fits old-school r&amp;b h...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>How to you make holy water? you boil the hell ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>How many optometrists does it take to screw in...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>Mcdonald's will officially kick off all-day br...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>An irish man walks on the street and ignores a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  humor\n",
       "0       Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
       "1       Watch: darvish gave hitter whiplash with slow ...  False\n",
       "2       What do you call a turtle without its shell? d...   True\n",
       "3           5 reasons the 2016 election feels so personal  False\n",
       "4       Pasco police shot mexican migrant from behind,...  False\n",
       "...                                                   ...    ...\n",
       "199995  Conor maynard seamlessly fits old-school r&b h...  False\n",
       "199996  How to you make holy water? you boil the hell ...   True\n",
       "199997  How many optometrists does it take to screw in...   True\n",
       "199998  Mcdonald's will officially kick off all-day br...  False\n",
       "199999  An irish man walks on the street and ignores a...   True\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('dataset.csv')\n",
    "#dataset = pd.read_csv('/kaggle/input/200k-short-texts-for-humor-detection/dataset.csv')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum words in a sentence: 62\n",
      "Average words: 12\n"
     ]
    }
   ],
   "source": [
    "lengths=[]\n",
    "\n",
    "for i in range(len(df.text)):\n",
    "    lengths.append(len(df.text[i].split(' ')))\n",
    "\n",
    "word_len=[]\n",
    "for i in range(len(df)):\n",
    "    word_len.append(len(df.text[i].split(' ')))\n",
    "print(\"Maximum words in a sentence:\",max(word_len))\n",
    "print(\"Average words:\",round(np.mean(word_len)))\n",
    "\n",
    "text=df.text.to_list()\n",
    "\n",
    "max_words=100000\n",
    "tok=tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=max_words,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True,\n",
    "    split=' ',\n",
    "    char_level=False,\n",
    "    oov_token=None,\n",
    "    document_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq=tok.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max([len(x) for x in train_seq])\n",
    "\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    train_seq,\n",
    "    maxlen=maxlen,\n",
    "    dtype='int32',\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    value=0.0\n",
    ")\n",
    "text_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100000\n",
       "1    100000\n",
       "Name: humor, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.humor=(df.humor==True)*1\n",
    "df.humor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(text_padded, df.humor,\n",
    "                                                  test_size=0.2, random_state=1729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000, 25), (160000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional,InputLayer,Embedding, Flatten,Input,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "\n",
    "model.add(Input(shape=[maxlen]))\n",
    "model.add(Embedding(max_words,128,input_length=maxlen))    \n",
    "\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(LSTM(200, return_sequences=True))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000118BA38CA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000118BA38CA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9092WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000118BB05F2E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000118BB05F2E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "625/625 [==============================] - 181s 286ms/step - loss: 0.2305 - accuracy: 0.9092 - val_loss: 0.1831 - val_accuracy: 0.9291\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 217s 347ms/step - loss: 0.1487 - accuracy: 0.9420 - val_loss: 0.1787 - val_accuracy: 0.9306\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 206s 329ms/step - loss: 0.1208 - accuracy: 0.9520 - val_loss: 0.1870 - val_accuracy: 0.9303\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 202s 323ms/step - loss: 0.1022 - accuracy: 0.9591 - val_loss: 0.2160 - val_accuracy: 0.9305\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 207s 331ms/step - loss: 0.0877 - accuracy: 0.9650 - val_loss: 0.2127 - val_accuracy: 0.9312\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 202s 322ms/step - loss: 0.0755 - accuracy: 0.9698 - val_loss: 0.2381 - val_accuracy: 0.9317\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 191s 305ms/step - loss: 0.0666 - accuracy: 0.9734 - val_loss: 0.2737 - val_accuracy: 0.9293\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 185s 295ms/step - loss: 0.0606 - accuracy: 0.9758 - val_loss: 0.2931 - val_accuracy: 0.9303\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 188s 300ms/step - loss: 0.0567 - accuracy: 0.9774 - val_loss: 0.2890 - val_accuracy: 0.9305\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 186s 298ms/step - loss: 0.0526 - accuracy: 0.9791 - val_loss: 0.3202 - val_accuracy: 0.9304\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 204s 327ms/step - loss: 0.0489 - accuracy: 0.9805 - val_loss: 0.3589 - val_accuracy: 0.9306\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 190s 304ms/step - loss: 0.0467 - accuracy: 0.9813 - val_loss: 0.4060 - val_accuracy: 0.9282\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 177s 283ms/step - loss: 0.0450 - accuracy: 0.9820 - val_loss: 0.3877 - val_accuracy: 0.9292\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 195s 311ms/step - loss: 0.0435 - accuracy: 0.9825 - val_loss: 0.4073 - val_accuracy: 0.9274\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 187s 299ms/step - loss: 0.0420 - accuracy: 0.9832 - val_loss: 0.5166 - val_accuracy: 0.9266\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 180s 288ms/step - loss: 0.0406 - accuracy: 0.9838 - val_loss: 0.3769 - val_accuracy: 0.9266\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 191s 306ms/step - loss: 0.0394 - accuracy: 0.9842 - val_loss: 0.4132 - val_accuracy: 0.9292\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 208s 333ms/step - loss: 0.0384 - accuracy: 0.9846 - val_loss: 0.4833 - val_accuracy: 0.9267\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 200s 321ms/step - loss: 0.0375 - accuracy: 0.9848 - val_loss: 0.5131 - val_accuracy: 0.9255\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 178s 285ms/step - loss: 0.0367 - accuracy: 0.9852 - val_loss: 0.4881 - val_accuracy: 0.9266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118ba396c80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,batch_size=256,validation_data=(X_test, Y_test),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   17,    12,    75, ...,     0,     0,     0],\n",
       "       [    9,    12,     4, ...,     0,     0,     0],\n",
       "       [  903, 12862,   676, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 8000,   898,  1050, ...,     0,     0,     0],\n",
       "       [    4,    91,  2492, ...,     0,     0,     0],\n",
       "       [ 2177,   357,   420, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=model.predict(X_test)\n",
    "\n",
    "print(\"All Probabilities:\\n\",Y_pred[0])\n",
    "print(\"\\nCorrect:\", Y_pred[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds=[]\n",
    "for i in range(len(Y_pred)):\n",
    "    Y_preds.append(Y_pred[i][-1])\n",
    "Y_preds=np.array(Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds=(Y_preds>0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=np.array(Y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(confusion_matrix(Y_preds,Y_test),annot=True,fmt='d',cmap='Blues')\n",
    "plt.title(\"Confusion Matrix, 0 signifies not sarcastic, 1 signifies sarcastic\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report:\", classification_report(Y_preds,Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
